{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python394jvsc74a57bd02647ea34e536f865ab67ff9ddee7fd78773d956cec0cab53c79b32cd10da5d83",
   "display_name": "Python 3.9.4 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Original tutorial: https://www.tutorialspoint.com/gensim/gensim_creating_lda_topic_model.htm<br>\n",
    "Secondary tutorial: https://radimrehurek.com/gensim/models/ldamodel.html"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore') #There is deprication warnings using VSCode I would rather avoid\n",
    "\n",
    "import re\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from pprint import pprint\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import spacy\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train')\n",
    "nlp = spacy.load('en_core_web_md', disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from','subject','re','edu','use'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))\n",
    "\n",
    "data = newsgroups_train.data\n",
    "data = [re.sub('\\S*@\\Ss?', '', sent) for sent in data]\n",
    "data = [re.sub('\\s+', ' ', sent) for sent in data]\n",
    "data = [re.sub(\"\\'\",\"\",sent) for sent in data]\n",
    "data_words = list(sent_to_words(newsgroups_train.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100)\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN','ADJ','VERB','ADV']):\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent))\n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out\n",
    "\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "data_lemmatized = lemmatization(data_words_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LDA model\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "texts = data_lemmatized\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "lda_model = gensim.models.ldamodel.LdaModel(\n",
    "    corpus=corpus\n",
    "    ,id2word=id2word\n",
    "    ,num_topics=20\n",
    "    ,random_state=100\n",
    "    ,update_every=1\n",
    "    ,chunksize=100\n",
    "    ,passes=10\n",
    "    ,alpha='auto'\n",
    "    ,per_word_topics=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "lda_model.save('20newsgroups_lda_t20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a model example\n",
    "lda_model = gensim.models.LdaModel.load('20newsgroups_lda_t20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[(4,\n",
       "  '0.067*\"cable\" + 0.049*\"sgi\" + 0.000*\"trunk\" + 0.000*\"jon\" + 0.000*\"wiring\"'),\n",
       " (7,\n",
       "  '0.090*\"m\" + 0.040*\"fi\" + 0.039*\"boy\" + 0.025*\"brave\" + 0.022*\"saturday\"'),\n",
       " (11,\n",
       "  '0.016*\"evidence\" + 0.011*\"case\" + 0.011*\"group\" + 0.010*\"book\" + 0.009*\"issue\"'),\n",
       " (8,\n",
       "  '0.033*\"say\" + 0.027*\"people\" + 0.019*\"god\" + 0.019*\"think\" + 0.014*\"believe\"'),\n",
       " (14,\n",
       "  '0.037*\"line\" + 0.036*\"com\" + 0.034*\"organization\" + 0.027*\"write\" + 0.022*\"get\"')]"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "#Print the topics\n",
    "lda_model.print_topics(num_topics=5, num_words=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Perplexity:  -14.328053890995294 \nCoherence Score:  0.5086267008315802\n"
     ]
    }
   ],
   "source": [
    "# Print some model stats\n",
    "coherence_model_lda = CoherenceModel(\n",
    "    model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v'\n",
    ")\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "\n",
    "print('Perplexity: ', lda_model.log_perplexity(corpus), '\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the model\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word)\n",
    "pyLDAvis.save_html(vis, '20newsgroups_lda_model_vis.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "([(2, 0.06496077), (3, 0.038348276), (6, 0.017036414), (8, 0.13890307), (9, 0.013866927), (10, 0.025442459), (11, 0.10610145), (13, 0.055529993), (14, 0.4666749), (17, 0.018005379)], [(99, [14, 2, 13]), (179, [14, 8, 11]), (23807, [])], [(99, [(2, 0.35869116), (13, 0.06876848), (14, 0.57246506)]), (179, [(8, 0.12819229), (11, 0.04464748), (14, 0.8271367)]), (23807, [])])\n"
     ]
    }
   ],
   "source": [
    "# Query the model using previously unseen texts\n",
    "other_texts = [\n",
    "    ['computer','time','graph']\n",
    "    ,['survey','response','eps']\n",
    "    ,['human','system','computer']\n",
    "]\n",
    "\n",
    "other_corpus = [id2word.doc2bow(text) for text in other_texts]\n",
    "vector = lda_model[other_corpus[0]]\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "([(2, 0.06872155), (3, 0.03776076), (6, 0.016843356), (8, 0.1387931), (9, 0.013720744), (10, 0.02510831), (11, 0.10827711), (13, 0.053645287), (14, 0.4646846), (17, 0.017797304)], [(99, [14, 2, 13]), (179, [14, 8, 11]), (23807, [])], [(99, [(2, 0.3840592), (13, 0.04543065), (14, 0.5704694)]), (179, [(8, 0.1192261), (11, 0.04241071), (14, 0.8383426)]), (23807, [])])\n"
     ]
    }
   ],
   "source": [
    "# update the model by incrementally training on the new corpus\n",
    "lda_model.update(other_corpus)\n",
    "vector = lda_model[other_corpus[0]]\n",
    "print(vector)"
   ]
  },
  {
   "source": [
    "### Determining the number of topics"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coherence_values_computation(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics, passes=10)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "cannot assign to literal (<ipython-input-37-84f2839a56c9>, line 1)",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-37-84f2839a56c9>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    start=1,limit=50, step=8\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m cannot assign to literal\n"
     ]
    }
   ],
   "source": [
    "start=1; limit=50; step=8\n",
    "\n",
    "model_list, coherence_values = coherence_values_computation(\n",
    "    corpus=corpus\n",
    "    ,dictionary=id2word\n",
    "    ,texts=data_lemmatized\n",
    "    ,start=start, limit=limit, step=step\n",
    ")\n",
    "\n",
    "plt.plot(x=range(start,limit,step), y=coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence values\"), loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}